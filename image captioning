import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Add


def load_feature_extractor():
    base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    return Model(inputs=base_model.input, outputs=base_model.output)

feature_extractor = load_feature_extractor()

def extract_features(image_path):
    img = load_img(image_path, target_size=(224, 224))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    features = feature_extractor.predict(img)
    return features.flatten()


def create_captioning_model(vocab_size, max_length):
    image_input = Input(shape=(2048,))
    image_features = Dense(256, activation='relu')(image_input)
    
    text_input = Input(shape=(max_length,))
    embedding = Embedding(vocab_size, 256, mask_zero=True)(text_input)
    lstm = LSTM(256)(embedding)
    
    merged = Add()([image_features, lstm])
    output = Dense(vocab_size, activation='softmax')(merged)
    
    model = Model(inputs=[image_input, text_input], outputs=output)
    model.compile(loss='categorical_crossentropy', optimizer='adam')
    return model
